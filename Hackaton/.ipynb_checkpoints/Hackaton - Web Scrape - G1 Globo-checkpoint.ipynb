{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrape - G1 Globo.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objetivo: extrair a headline, descrição e link das principais notícias do portal G1 Globo afim de identificar padrões referentes à notícias verdadeiras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando listas vazias com os campos que queremos extrair do portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = []\n",
    "link_list = []\n",
    "summary_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desenvolvemos uma função para extrair os dados de forma iterativa por todas as páginas do portal. Importante salientar que cada portal de notícias possui uma estrutura única.\n",
    "\n",
    "Portanto, para cada portal, desenvolvemos uma função diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScrapeFakeNews(url):\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page,'html.parser')\n",
    "    \n",
    "    summaries = soup.find_all('div', {'class': 'type-materia'})\n",
    "    titles = soup.find_all('div', {'class': 'type-materia'})\n",
    "    links = soup.find_all('div', {'class': 'type-materia'})\n",
    "\n",
    "    for title in titles:\n",
    "        title_list.append(title.find('p', {'class': 'feed-post-body-title'}).get_text())\n",
    "        \n",
    "    for link in links:\n",
    "        link_list.append(link.find('a' , {'class': 'feed-post-link'}).get('href'))\n",
    "\n",
    "    for summary in summaries:\n",
    "        summary_list.append(summary.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScrapeFakeNews('http://g1.globo.com/politica/index/feed/pagina-1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteração com todas as páginas do website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1834/1834 [13:48<00:00,  2.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "  \n",
    "for x in tqdm(range(2,1836)):\n",
    "    paginas = 'http://g1.globo.com/politica/index/feed/pagina-' + str(x) +'.html'\n",
    "    \n",
    "    try: \n",
    "        ScrapeFakeNews(paginas)\n",
    "    except (RuntimeError, TypeError, NameError):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o DataFrame baseado nos dados extraídos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_final = np.array(title_list)\n",
    "url_final = np.array(link_list)\n",
    "summary_final = np.array(summary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = pd.DataFrame(data=[title_final, url_final, summary_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_real = g1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_real.columns = ['title', 'url', 'summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraindo o DataFrame para CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_real.to_csv('g1.csv')\\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
